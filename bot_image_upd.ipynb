{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794ca429-f36f-4a8a-8762-30a6d63d3363",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, norm, spearmanr, pearsonr, ttest_ind\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3edabcc7-ac86-4dc7-8446-498e7f3b3ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if datetime.today().weekday()+1!=1:\n",
    "  exit \n",
    "else:\n",
    "  params={}\n",
    "  params['global_start']=datetime.strftime(datetime.today()-timedelta(7),format='%Y-%m-%d')\n",
    "  params['global_end']=datetime.strftime(datetime.today()-timedelta(1),format='%Y-%m-%d')\n",
    "\n",
    "  params['global_start_ly']=datetime.strftime(datetime.today()-timedelta(7+364),format='%Y-%m-%d')\n",
    "  params['global_end_ly']=datetime.strftime(datetime.today()-timedelta(1+364),format='%Y-%m-%d')\n",
    "\n",
    "  params['subq']=\"\"\" select * from delta.`/mnt/datalake/data/gold/DepartmentUnitsInfo` where businessid='DodoPizza' \"\"\"\n",
    "\n",
    "  query=\"\"\"\n",
    "  select \n",
    "  b.countryid, 'ty' as period, unitid,  \n",
    "  count(distinct orderid) as tickets, sum(cast(producttotalprice as float)) as rto, count(*) as qty, sum(cast(menuprice as float)) as rto_do\n",
    "  from\n",
    "  (select * from delta.`/mnt/datalake/data/gold/OrderCompositionExtendedWithCombo`\n",
    "  where \n",
    "  categoryid>0 and date>='{global_start}' and date<='{global_end}' and businessid='DodoPizza' and categoryid!=5) a\n",
    "    inner join ({subq}) b on a.unituuid=b.uuid\n",
    "  group by\n",
    "  b.countryid, unitid\n",
    "\n",
    "  union all\n",
    "\n",
    "  select \n",
    "  b.countryid, 'ly' as period, unitid, \n",
    "  count(distinct orderid) as tickets, sum(cast(producttotalprice as float)) as rto, count(*) as qty, sum(cast(menuprice as float)) as rto_do\n",
    "  from\n",
    "  (select * from delta.`/mnt/datalake/data/gold/OrderCompositionExtendedWithCombo`\n",
    "  where \n",
    "  categoryid>0 and date>='{global_start_ly}' and date<='{global_end_ly}' and businessid='DodoPizza'and categoryid!=5) a \n",
    "    inner join ({subq}) b on a.unituuid=b.uuid\n",
    "  group by\n",
    "  b.countryid, unitid\"\"\".format(**params)\n",
    "  df_lfl=spark.sql(query).toPandas()\n",
    "\n",
    "\n",
    "  df_lfl=pd.merge(df_lfl.groupby(['countryid','unitid'])[['period']].count().query('period==2').reset_index().iloc[:,:2],\n",
    "          df_lfl,\n",
    "          how='inner',\n",
    "          on=['countryid','unitid']\n",
    "  )\n",
    "\n",
    "  df_lfl_ty=df_lfl.query('period==\"ty\"').drop('period', axis='columns')\n",
    "  df_lfl_ly=df_lfl.query('period==\"ly\"').drop('period', axis='columns')\n",
    "\n",
    "  df_lfl=pd.merge(df_lfl_ty, df_lfl_ly, how='inner', on=['countryid','unitid'], suffixes=('_ty','_ly'))\n",
    "\n",
    "  df_lfl=df_lfl.groupby('countryid', as_index=False).agg('sum').drop('unitid',axis='columns')\n",
    "\n",
    "  for i in ['_ty','_ly']:\n",
    "    df_lfl['avg_price_do'+i]=df_lfl['rto_do'+i]/df_lfl['qty'+i]\n",
    "    df_lfl['complexity'+i]=df_lfl['qty'+i]/df_lfl['tickets'+i]\n",
    "    df_lfl['discount'+i]=(df_lfl['rto_do'+i]-df_lfl['rto'+i])/df_lfl['rto_do'+i]\n",
    "\n",
    "\n",
    "  query=\"\"\"\n",
    "  select \n",
    "  b.countryid, 'ty' as period, unitid, productid, count(*) as qty, sum(cast(menuprice as float)) as rto_do\n",
    "  from\n",
    "  (select * from delta.`/mnt/datalake/data/gold/OrderCompositionExtendedWithCombo`\n",
    "  where categoryid>0 and date>='{global_start}' and date<='{global_end}' and incombo=0 and businessid='DodoPizza' and categoryid!=5) a inner join ({subq}) b on a.unituuid=b.uuid\n",
    "  group by\n",
    "  b.countryid, unitid, productid\n",
    "\n",
    "  union all\n",
    "\n",
    "  select \n",
    "  b.countryid, 'ly' as period, unitid, productid, count(*) as qty, sum(cast(menuprice as float)) as rto_do\n",
    "  from\n",
    "  (select * from delta.`/mnt/datalake/data/gold/OrderCompositionExtendedWithCombo`\n",
    "  where categoryid>0 and date>='{global_start_ly}' and date<='{global_end_ly}' and incombo=0 and businessid='DodoPizza' and categoryid!=5) a inner join ({subq}) b on a.unituuid=b.uuid\n",
    "  group by\n",
    "  b.countryid, unitid, productid\"\"\".format(**params)\n",
    "  df_infl=spark.sql(query).toPandas()\n",
    "\n",
    "  df_infl=pd.merge(df_infl.groupby(['countryid','unitid'])[['period']].nunique().query('period==2').reset_index().iloc[:,:2],\n",
    "          df_infl,\n",
    "          how='inner',\n",
    "          on=['countryid','unitid']\n",
    "  )\n",
    "\n",
    "  df_infl=df_infl.groupby(['countryid','period','productid'], as_index=False).agg({'qty':'sum','rto_do':'sum'})\n",
    "\n",
    "  df_infl=pd.merge(df_infl.query('period==\"ty\"').drop('period',axis='columns'), \n",
    "          df_infl.query('period==\"ly\"').drop('period',axis='columns'),\n",
    "          how='inner',\n",
    "          on=['countryid','productid'],\n",
    "          suffixes=('_ty','_ly')\n",
    "          )\n",
    "\n",
    "\n",
    "  df_infl['price_ly']=df_infl['rto_do_ly']/df_infl['qty_ly']\n",
    "  df_infl['rto_do_ty_to_be']=df_infl['price_ly']*df_infl['qty_ty']\n",
    "\n",
    "  df_infl=pd.DataFrame(df_infl.groupby('countryid')[['rto_do_ty','rto_do_ty_to_be']].sum().apply(lambda x: x['rto_do_ty']/x['rto_do_ty_to_be']-1, axis=1), columns=['inflation'])\n",
    "\n",
    "  df_lfl=pd.merge(df_lfl, df_infl.reset_index(), how='inner', on='countryid')\n",
    "\n",
    "  df_lfl['price_do_chg']=df_lfl['avg_price_do_ty']/df_lfl['avg_price_do_ly']-1\n",
    "  df_lfl['mix']=(1+df_lfl['price_do_chg'])/(1+df_lfl['inflation'])-1\n",
    "  df_lfl['rto_lfl_chg_as_is']=df_lfl['rto_ty']/df_lfl['rto_ly']-1\n",
    "\n",
    "\n",
    "  bl=df_lfl['rto_ly']\n",
    "  df_lfl['tickets_impact']=df_lfl['rto_lfl_chg_as_is']-\\\n",
    "            ((df_lfl['tickets_ly']*df_lfl['complexity_ty']*df_lfl['avg_price_do_ly']*(1+df_lfl['inflation'])*(1+df_lfl['mix'])*(1-df_lfl['discount_ty']))/bl-1)\n",
    "\n",
    "\n",
    "  df_lfl['complexity_impact']=df_lfl['rto_lfl_chg_as_is']-\\\n",
    "            ((df_lfl['tickets_ty']*df_lfl['complexity_ly']*df_lfl['avg_price_do_ly']*(1+df_lfl['inflation'])*(1+df_lfl['mix'])*(1-df_lfl['discount_ty']))/bl-1)\n",
    "    \n",
    "\n",
    "  df_lfl['inflation_impact']=df_lfl['rto_lfl_chg_as_is']-\\\n",
    "            ((df_lfl['tickets_ty']*df_lfl['complexity_ty']*df_lfl['avg_price_do_ly']*(1+df_lfl['mix'])*(1-df_lfl['discount_ty']))/bl-1)\n",
    "    \n",
    "\n",
    "  df_lfl['mix_impact']=df_lfl['rto_lfl_chg_as_is']-\\\n",
    "            ((df_lfl['tickets_ty']*df_lfl['complexity_ty']*df_lfl['avg_price_do_ly']*(1+df_lfl['inflation'])*(1-df_lfl['discount_ty']))/bl-1)\n",
    "    \n",
    "\n",
    "  df_lfl['discount_impact']=df_lfl['rto_lfl_chg_as_is']-\\\n",
    "            ((df_lfl['tickets_ty']*df_lfl['complexity_ty']*df_lfl['avg_price_do_ly']*(1+df_lfl['inflation'])*(1+df_lfl['mix'])*(1-df_lfl['discount_ly']))/bl-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43a15a1c-eb51-4331-a6f2-37a9a14dbba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(nrows=1, ncols=1, figsize=(9,5))\n",
    "fig.suptitle('Sales LFL decomposition by key factors', y=1.04, fontweight='bold')\n",
    "\n",
    "df_temp=df_lfl.set_index('countryid').sort_values(by='rto_lfl_chg_as_is', ascending=False).iloc[:, -5:]\n",
    "df_temp.columns=[x.replace('_impact','') for x in df_temp.columns]\n",
    "df_temp.plot(kind='bar', stacked=True, ax=ax, alpha=0.7)\n",
    "\n",
    "for c in ax.containers:\n",
    "    labels = [np.round(v.get_height()*100,1) for v in c]\n",
    "    ax.bar_label(c, labels=labels, label_type='center', fontsize=8)\n",
    "\n",
    "\n",
    "df_lfl.set_index('countryid').sort_values(by='rto_lfl_chg_as_is', ascending=False).rename(columns={'rto_lfl_chg_as_is':'lfl total'})['lfl total'].plot(ax=ax, marker='.', color='black')\n",
    "ax.axhline(0, color='black')\n",
    "ax.grid(linestyle='--', alpha=0.4)\n",
    "\n",
    "ax.set_xlabel('countries sorted by LFL', backgroundcolor='lightgrey')\n",
    "ax.set_ylabel('LFL %', backgroundcolor='lightgrey')\n",
    "\n",
    "ax.legend(bbox_to_anchor=(1.25,1), frameon=False)\n",
    "\n",
    "vals = ax.get_yticks()\n",
    "ax.set_yticklabels(['{:,.1%}'.format(x) for x in vals])\n",
    "\n",
    "ax.tick_params(axis='x', labelrotation = 0)\n",
    "\n",
    "ax.text(x=0, y=1.05, s='Week TY: '+params['global_start']+'...'+params['global_end'], transform=ax.transAxes)\n",
    "ax.text(x=0, y=1.01, s='Week LY: '+params['global_start_ly']+'...'+params['global_end_ly'], transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50b56ef3-d356-4c8d-b143-6a6cab96d75e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp=datetime.strftime(datetime.today(),'%m%d%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fc5ef86-72de-46eb-b3e2-ef748f4cb983",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig.savefig(fname= f\"/Workspace/Repos/a.tarasov@dodopizza.com/analytic_images/images/output_images_{tmp}.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f82a276-db6a-4e1a-a933-0cffb57e783a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "message1 = f\"![Данные за прошлую неделю](https://github.com/alextarasov90/analytic_images/blob/main/images/output_images_{tmp}.jpg?raw=true)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "735456dd-cd77-46f0-9ff6-4594d8749143",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Specify Mattermost webhook url to send message\n",
    "    url = \"https://dodobrands.loop.ru/hooks/fsic3xmaq7rhfrfd13hmfrs9ha\"\n",
    "\n",
    "    # Create message payload per mattrermost API documentation:\n",
    "    # https://docs.mattermost.com/developer/webhooks-incoming.html#parameters-and-formatting\n",
    "    messages = [\n",
    "        {\n",
    "             'username': 'CVM cat',\n",
    "             'icon_url': 'https://i.ibb.co/LQMSBCh/udivl-nnaya-morda-malenkogo-kotenka.jpg',\n",
    "             'text'    : message1\n",
    "             \n",
    "             \n",
    "        }\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Post above messages!\n",
    "    for message in messages:\n",
    "        post_to_mattermost(url, json.dumps(message))\n",
    "\n",
    "def post_to_mattermost(url, message):\n",
    "    # Send payload as HTTP Post Request to Webhook URL\n",
    "    r = requests.post(\n",
    "        url,\n",
    "        data=message\n",
    "    )\n",
    "    r.raise_for_status()\n",
    "\n",
    "if (__name__) == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a01e366-ed81-4652-ab91-b4b2cb9d193a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 566422136249412,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "bot_image_upd",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
